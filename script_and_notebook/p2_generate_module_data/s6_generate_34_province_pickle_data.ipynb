{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.699965Z",
     "start_time": "2025-07-23T19:13:06.345411Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from vietunits.utils import key_normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = Path().resolve().parent.parent"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.713710Z",
     "start_time": "2025-07-23T19:13:06.711396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IDEA\n",
    "data = {\n",
    "    'thanhphohochiminh': {'keywords': ['thanhphohochiminh', 'hochiminh', 'hcm']},\n",
    "    'hanoi': {'keywords': ['hanoi', 'hn']},\n",
    "}\n",
    "\n",
    "# Bước 1: Tạo list keyword, sắp xếp theo độ dài giảm dần\n",
    "keywords = sorted(\n",
    "    [kw for v in data.values() for kw in v['keywords']],\n",
    "    key=len,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Bước 2: Tạo regex pattern\n",
    "pattern = re.compile('|'.join(re.escape(k) for k in keywords), flags=re.IGNORECASE)\n",
    "\n",
    "# Bước 3: Kiểm tra chuỗi address\n",
    "address = 'quan5, hcm'\n",
    "\n",
    "match = pattern.search(address)\n",
    "keyword = match.group(0) if match else None\n",
    "\n",
    "# Bước 4: Tìm key trong data tương ứng với keyword\n",
    "data_key = next((k for k, v in data.items() if keyword and keyword.lower() in [kw.lower() for kw in v['keywords']]), None)\n",
    "\n",
    "print(data_key)"
   ],
   "id": "5532343fd0fcded1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thanhphohochiminh\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.727190Z",
     "start_time": "2025-07-23T19:13:06.723460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_sort(text, level=1):\n",
    "    if isinstance(text, str):\n",
    "        if level == 1:\n",
    "            text = re.sub(r'^Tỉnh\\s|Thành phố\\s', '', text, flags=re.IGNORECASE)\n",
    "        elif level == 2:\n",
    "            if re.search(r'^Quận\\s\\d{1,2}', text, flags=re.IGNORECASE):\n",
    "                pass\n",
    "            else:\n",
    "                text = re.sub(r'^Quận\\s|Huyện\\s|Thị xã\\s|Thành phố\\s', '', text, flags=re.IGNORECASE)\n",
    "        else:\n",
    "            if re.search(r'^Phường\\s\\d{1,2}', text, flags=re.IGNORECASE):\n",
    "                pass\n",
    "            else:\n",
    "                text = re.sub(r'^Phường\\s|Thị trấn\\s|Xã\\s', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "        return text.strip()\n",
    "    return text\n",
    "\n",
    "district_type_acronym = {\n",
    "    'Quận': 'q',\n",
    "    'Thị xã': 'tx',\n",
    "    'Thành phố': 'tp',\n",
    "    'Huyện': 'h',\n",
    "}\n",
    "ward_type_acronym = {\n",
    "    'Phường': 'p',\n",
    "    'Thị trấn': 'tt',\n",
    "    'Xã': 'x'\n",
    "}\n",
    "def create_keywords(row, level=1):\n",
    "    keywords = []\n",
    "    if level == 1:\n",
    "        keywords.append(row['provinceKey'])\n",
    "        keywords.append(row['provinceShortKey'])\n",
    "        if pd.notnull(row['provinceAlias']):\n",
    "            aliases = json.loads(row['provinceAlias'])\n",
    "            for a in aliases:\n",
    "                keywords.append(key_normalize(a))\n",
    "\n",
    "    elif level == 2:\n",
    "        keywords.append(row['districtKey'])\n",
    "        if not row['districtShortKeyDuplicated']:\n",
    "            keywords.append(row['districtShortKey'])\n",
    "        else:\n",
    "            keywords.append(key_normalize(f\"{row['districtShortKey']} {row['districtType']}\"))\n",
    "            keywords.append(key_normalize(f\"{district_type_acronym[row['districtType']]}.{row['districtShortKey']}\"))\n",
    "\n",
    "        if pd.notnull(row['districtAlias']):\n",
    "            aliases = json.loads(row['districtAlias'])\n",
    "            for a in aliases:\n",
    "                keywords.append(key_normalize(a))\n",
    "\n",
    "        if re.search(r'^quan\\d{1,2}', row['districtKey'], flags=re.IGNORECASE):\n",
    "            keywords.append(row['districtKey'].replace('quan', 'q'))\n",
    "            keywords.append(row['districtKey'].replace('quan', 'q.'))\n",
    "            keywords.append(row['districtKey'].replace('quan', 'district'))\n",
    "\n",
    "    else:\n",
    "        if pd.notnull(row['wardKey']):\n",
    "            keywords.append(row['wardKey'])\n",
    "            if not row['wardShortKeyDuplicated']:\n",
    "                keywords.append(row['wardShortKey'])\n",
    "            else:\n",
    "                keywords.append(key_normalize(f\"{row['wardShortKey']} {row['wardType']}\"))\n",
    "                keywords.append(key_normalize(f\"{ward_type_acronym[row['wardType']]}.{row['wardShortKey']}\"))\n",
    "\n",
    "            if pd.notnull(row['wardAlias']):\n",
    "                aliases = json.loads(row['wardAlias'])\n",
    "                for a in aliases:\n",
    "                    keywords.append(key_normalize(a))\n",
    "\n",
    "            if re.search(r'^phuong\\d{1,2}', row['wardKey'], flags=re.IGNORECASE):\n",
    "                keywords.append(row['wardKey'].replace('phuong', 'p'))\n",
    "                keywords.append(row['wardKey'].replace('phuong', 'p.'))\n",
    "                keywords.append(row['wardKey'].replace('phuong', 'ward'))\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    keywords = list(set(keywords))\n",
    "    keywords = sorted(keywords, key=len, reverse=True)\n",
    "    return json.dumps(keywords)"
   ],
   "id": "d9cb61191932a1ae",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.755098Z",
     "start_time": "2025-07-23T19:13:06.734573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_convert = pd.read_csv(BASE_DIR / 'data/danhmuc_and_sapnhap_has_default_new_ward.csv')\n",
    "cols = [\n",
    "    'provinceCode',\n",
    "    'districtCode',\n",
    "    'districtType',\n",
    "    'wardCode',\n",
    "    'wardType',\n",
    "    'province',\n",
    "    'district',\n",
    "    'ward'\n",
    "]\n",
    "df = df_convert[cols].drop_duplicates().reset_index(drop=True)"
   ],
   "id": "36da00036467b7ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.910045Z",
     "start_time": "2025-07-23T19:13:06.762490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ENRICH DATA\n",
    "unit_cols = ['province', 'district', 'ward']\n",
    "level_map = {\n",
    "    'province': 1,\n",
    "    'district': 2,\n",
    "    'ward': 3\n",
    "}\n",
    "\n",
    "for col in unit_cols:\n",
    "    # Create short version\n",
    "    level = level_map[col]\n",
    "    df[f\"{col}Short\"] = df[col].apply(create_sort, args=(level,))\n",
    "\n",
    "    # Create key\n",
    "    df[f\"{col}Key\"] = df[f\"{col}\"].apply(key_normalize)\n",
    "\n",
    "    # Create short key\n",
    "    df[f\"{col}ShortKey\"] = df[f\"{col}Short\"].apply(key_normalize)"
   ],
   "id": "4ec7833006a03977",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.921878Z",
     "start_time": "2025-07-23T19:13:06.917108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -- CREATE ALIAS\n",
    "# Khởi tạo cột alias rỗng\n",
    "for col in ['province', 'district', 'ward']:\n",
    "    df[f\"{col}Alias\"] = np.nan\n",
    "\n",
    "# Province alias data\n",
    "province_alias_data = {\n",
    "    'thanhphohanoi': ['hn'],\n",
    "    'thanhphohochiminh': ['hcm'],\n",
    "    'tinhbariavungtau': ['baria', 'vungtau'],\n",
    "}\n",
    "\n",
    "# District alias data (theo từng province)\n",
    "district_alias_data = {\n",
    "    'thanhphohochiminh': {\n",
    "        'thanhphothuduc': ['quan9', 'quan2']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ward alias data (theo từng province > district > ward)\n",
    "ward_alias_data = {\n",
    "    # 'thanhphohochiminh': {\n",
    "    #     'thanhphothuduc': {\n",
    "    #         'phuongtruongthanh': ['truongthanh', 'p.truongthanh']\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Gán provinceAlias\n",
    "for key, value in province_alias_data.items():\n",
    "    df.loc[df['provinceKey'] == key, 'provinceAlias'] = json.dumps(value)\n",
    "\n",
    "# Gán districtAlias\n",
    "for province_key, district_data in district_alias_data.items():\n",
    "    for district_key, value in district_data.items():\n",
    "        df.loc[\n",
    "            (df['provinceKey'] == province_key) & (df['districtKey'] == district_key),\n",
    "            'districtAlias'\n",
    "        ] = json.dumps(value)\n",
    "\n",
    "# Gán wardAlias\n",
    "for province_key, district_data in ward_alias_data.items():\n",
    "    for district_key, ward_data in district_data.items():\n",
    "        for ward_key, value in ward_data.items():\n",
    "            df.loc[\n",
    "                (df['provinceKey'] == province_key) &\n",
    "                (df['districtKey'] == district_key) &\n",
    "                (df['wardKey'] == ward_key),\n",
    "                'wardAlias'\n",
    "            ] = json.dumps(value)"
   ],
   "id": "5671d46499cf16dd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.932869Z",
     "start_time": "2025-07-23T19:13:06.929441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicate district keys\n",
    "df_district = df[['province', 'provinceKey', 'district', 'districtKey', 'districtShortKey']].drop_duplicates()"
   ],
   "id": "2e2469c2ee8fe85b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.944951Z",
     "start_time": "2025-07-23T19:13:06.940279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check district key\n",
    "df_district.groupby(['province', 'districtKey']).size().reset_index(name='count').sort_values(by=['count'], ascending=False).head()\n",
    "# District key is unique"
   ],
   "id": "9faac47fc5e2a5a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              province     districtKey  count\n",
       "0    Thành phố Cần Thơ       huyencodo      1\n",
       "467     Tỉnh Quảng Nam    huyenphuninh      1\n",
       "459     Tỉnh Quảng Nam   huyenbactramy      1\n",
       "460     Tỉnh Quảng Nam     huyendailoc      1\n",
       "461     Tỉnh Quảng Nam  huyendonggiang      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>districtKey</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thành phố Cần Thơ</td>\n",
       "      <td>huyencodo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>huyenphuninh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>huyenbactramy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>huyendailoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>huyendonggiang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:06.991847Z",
     "start_time": "2025-07-23T19:13:06.985009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check district short key\n",
    "count_district_short_key = df_district.groupby(['province', 'districtShortKey']).size().reset_index(name='count').sort_values(by=['count'], ascending=False)\n",
    "duplicated_district_short_key = count_district_short_key[count_district_short_key['count']>1].copy()\n",
    "duplicated_district_short_key['districtShortKeyDuplicated'] = True\n",
    "duplicated_district_short_key.drop(columns=['count'], inplace=True)\n",
    "\n",
    "df = pd.merge(df, duplicated_district_short_key, on=['province', 'districtShortKey'], how='left')\n",
    "df['districtShortKeyDuplicated'].fillna(False, inplace=True)"
   ],
   "id": "943d997158461ec0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.015232Z",
     "start_time": "2025-07-23T19:13:07.011178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicated ward short key\n",
    "df_ward = df[['province', 'district', 'wardKey', 'wardShortKey']].drop_duplicates()"
   ],
   "id": "a302fed6c222b10d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.036875Z",
     "start_time": "2025-07-23T19:13:07.030070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check wardKey\n",
    "df_ward.groupby(['province', 'district', 'wardKey']).size().reset_index(name='count').sort_values(by=['count'], ascending=False).head()\n",
    "# wardKey is unique"
   ],
   "id": "1f1d4d9352186aa1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               province          district      wardKey  count\n",
       "0     Thành phố Cần Thơ       Huyện Cờ Đỏ  thitrancodo      1\n",
       "6679     Tỉnh Quảng Nam  Thành phố Hội An  phuongcaman      1\n",
       "6672     Tỉnh Quảng Nam     Huyện Đại Lộc   xadainghia      1\n",
       "6673     Tỉnh Quảng Nam     Huyện Đại Lộc   xadaiphong      1\n",
       "6674     Tỉnh Quảng Nam     Huyện Đại Lộc   xadaiquang      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>district</th>\n",
       "      <th>wardKey</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thành phố Cần Thơ</td>\n",
       "      <td>Huyện Cờ Đỏ</td>\n",
       "      <td>thitrancodo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>Thành phố Hội An</td>\n",
       "      <td>phuongcaman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>Huyện Đại Lộc</td>\n",
       "      <td>xadainghia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>Huyện Đại Lộc</td>\n",
       "      <td>xadaiphong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>Tỉnh Quảng Nam</td>\n",
       "      <td>Huyện Đại Lộc</td>\n",
       "      <td>xadaiquang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.087158Z",
     "start_time": "2025-07-23T19:13:07.078165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check duplicated short key\n",
    "count_ward_short_key = df_ward.groupby(['province', 'district', 'wardShortKey']).size().reset_index(name='count').sort_values(by=['count'], ascending=False)\n",
    "duplicated_ward_short_key = count_ward_short_key[count_ward_short_key['count']>1].copy()\n",
    "duplicated_ward_short_key['wardShortKeyDuplicated'] = True\n",
    "duplicated_ward_short_key.drop(columns=['count'], inplace=True)\n",
    "\n",
    "df = pd.merge(df, duplicated_ward_short_key, on=['province', 'district', 'wardShortKey'], how='left')\n",
    "df['wardShortKeyDuplicated'].fillna(False, inplace=True)"
   ],
   "id": "6e6178c11bc2ff3d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.251946Z",
     "start_time": "2025-07-23T19:13:07.106541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create keywords\n",
    "for col in unit_cols:\n",
    "    level = level_map[col]\n",
    "    df[f\"{col}Keywords\"] = df.apply(lambda row: create_keywords(row, level=level), axis=1)"
   ],
   "id": "ff6eb7d9e325cc71",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.501898Z",
     "start_time": "2025-07-23T19:13:07.269056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Province map\n",
    "df_province = df[['provinceKey', 'provinceKeywords', 'province', 'provinceShort']].drop_duplicates().reset_index(drop=True)\n",
    "DICT_PROVINCE = {}\n",
    "for _, row in df_province.iterrows():\n",
    "    DICT_PROVINCE[row['provinceKey']] = {\n",
    "        'provinceKeywords': json.loads(row['provinceKeywords']),\n",
    "        'province': row['province'],\n",
    "        'provinceShort': row['provinceShort'],\n",
    "    }\n",
    "\n",
    "\n",
    "# District map\n",
    "df_district = df[['provinceKey', 'provinceShortKey', 'districtKey', 'districtShortKey', 'districtKeywords', 'district', 'districtType', 'districtShort']].drop_duplicates().reset_index(drop=True)\n",
    "DICT_PROVINCE_DISTRICT = {}\n",
    "for _, province_row in df_province.iterrows():\n",
    "    province_key = province_row['provinceKey']\n",
    "    DICT_PROVINCE_DISTRICT[province_key] = {}\n",
    "\n",
    "    df_district_filtered = df_district[df_district['provinceKey'] == province_key]\n",
    "\n",
    "    for _, district_row in df_district_filtered.iterrows():\n",
    "        DICT_PROVINCE_DISTRICT[province_key][district_row['districtKey']] = {\n",
    "            'districtKeywords': json.loads(district_row['districtKeywords']) if pd.notnull(district_row['districtKeywords']) else [],\n",
    "            'district': district_row['district'],\n",
    "            'districtType': district_row['districtType'],\n",
    "            'districtShort': district_row['districtShort'],\n",
    "        }\n",
    "\n",
    "\n",
    "# Unique district to province map\n",
    "province_short_keys = df['provinceShortKey'].unique().tolist()\n",
    "for index, row in df_district.iterrows():\n",
    "    district_short_key = row['districtShortKey']\n",
    "    left_district_short_keys = df_district.loc[df_district.index != index, 'districtShortKey'].tolist()\n",
    "    if district_short_key not in province_short_keys and district_short_key not in left_district_short_keys:\n",
    "        df_district.loc[index, 'districtUnique'] = True\n",
    "df_district['districtUnique'].fillna(False, inplace=True)\n",
    "DICT_UNIQUE_DISTRICT_PROVINCE = {}\n",
    "for _, row in df_district.iterrows():\n",
    "    DICT_UNIQUE_DISTRICT_PROVINCE[row['districtKey']] = {\n",
    "        'districtKeywords': json.loads(row['districtKeywords']),\n",
    "        'provinceKey': row['provinceKey']\n",
    "    }\n",
    "\n",
    "\n",
    "# Ward map\n",
    "df_ward = df[['provinceKey', 'districtKey', 'wardKey', 'wardKeywords', 'ward', 'wardShort', 'wardType']].drop_duplicates().reset_index(drop=True)\n",
    "DICT_PROVINCE_DISTRICT_WARD = {}\n",
    "for province_key, province_group in df_ward.groupby('provinceKey'):\n",
    "    DICT_PROVINCE_DISTRICT_WARD[province_key] = {}\n",
    "\n",
    "    for district_key, district_group in province_group.groupby('districtKey'):\n",
    "        DICT_PROVINCE_DISTRICT_WARD[province_key][district_key] = {}\n",
    "\n",
    "        for _, row in district_group.iterrows():\n",
    "            ward_key = row['wardKey']\n",
    "            DICT_PROVINCE_DISTRICT_WARD[province_key][district_key][ward_key] = {\n",
    "                'wardKeywords': json.loads(row['wardKeywords']) if pd.notnull(row['wardKeywords']) else [],\n",
    "                'ward': row['ward'],\n",
    "                'wardShort': row['wardShort'],\n",
    "                'wardType': row['wardType'],\n",
    "            }"
   ],
   "id": "468514bf3b53a00c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.516849Z",
     "start_time": "2025-07-23T19:13:07.515419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pickle_data = {\n",
    "    'DICT_PROVINCE': DICT_PROVINCE,\n",
    "    'DICT_PROVINCE_DISTRICT': DICT_PROVINCE_DISTRICT,\n",
    "    'DICT_UNIQUE_DISTRICT_PROVINCE': DICT_UNIQUE_DISTRICT_PROVINCE,\n",
    "    'DICT_PROVINCE_DISTRICT_WARD': DICT_PROVINCE_DISTRICT_WARD\n",
    "}"
   ],
   "id": "b44bba4c4a137610",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:13:07.538122Z",
     "start_time": "2025-07-23T19:13:07.531032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(BASE_DIR / 'vietunits/data/v63provinces/pickle_data.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_data, f)"
   ],
   "id": "e5e25e4755505953",
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
